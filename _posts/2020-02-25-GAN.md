---
layout: post
title:  "GAN : Generative Adversarial Nets"
subtitle:   "Paper Review"
categories: Artificial_Intelligence
comments: true

---

### Generative Adversarial Nets

>  이 게시글은  ` Ian J.Goodfellow ` 이 작성한 [Generative Adversarial Nets](https://arxiv.org/pdf/1406.2661.pdf) 논문을 리뷰한 것으로 잘못된 부분이 있을 수 있음을 알리는 바입니다.

  오늘 리뷰할 논문은 `Generative Adversarial Nets` 로 2014년에 `Ian Goodfellow` 가 처음 논문을 발표하였을 때부터 2020년 지금까지 핫한 GAN 이라는 주제의 시작을 알린 신호탄이라고 볼 수 있습니다. 

  현재 GAN은 이미지에서부터 음성,문자에 이르기 까지 다양한 분야에 적용되고 있습니다. 이 글에선 이렇게 다양한 용도로 쓰이는  GAN이 무엇인지, 어떤 원리로 그림을 생성하는지, 그리고 논문에 쓰여진 수식을 이해하는 것을 목표로 진행 합니다. 



> 이 논문의 핵심 내용은 아래와 같습니다.
>
> 1. GAN의 개념
> 2. GAN 모델이 global minimum으로 최적화되어 있고, unique한 답이 있을 경우 -log4로 수렴함을 증명



#### GAN의 기본 개념

GAN은 이름에서부터 대략적인 유추가 가능합니다.

`Generative model` 은 이름에서부터 무언가를 생성하는 모델인 것을 유추할 수 있습니다. 실제 `class` 를 분류하는 `classifier` 과 달리 특정한 데이터를 만들어내는 방법을 배우는 모델입니다. 

`Adversarial model` 에서 Adversarial은 `대립하는` ,`적대하는` 이라는 의미입니다. 대립 하려면 상대방이 존재해야함으로 GAN은 크게 두 부분으로 구조를 나눈다고 생각할 수 있습니다. 실제로 `GAN` 은 `Generative mdoel` 과 `Adversarial model` 을 경쟁시켜 더 좋은 결과를 유도해냅니다.

이 논문에서 저자 `Ian Goodfellow` 는 `위조지폐범 `과 `경찰` 을예시로 쉽게 설명을 하고 있습니다. `위조지폐범` 은 `Generator(이하 G)`, 경찰은 `Discriminator(이하 D)` 입니다.

`위조지폐범(G)` 은 위조지폐를 실제 지폐와 구분 못하게 만들어 `경찰(D)` 를 최대한 속이는 것이 목표이며 , `경찰(D)` 은 위조지폐를 정확하게 감별하는 것이 목표입니다. 이 두 모델은 서로 경쟁적으로 학습하여 결국 진짜 지폐와 위조 지폐를 구분 못하는 상황에 이르게 된다고 설명합니다. 

조금 더 이론적으로 들어가보면, `Generative model G` 는 학습 데이터 X의 분포를 카피하는 방향으로 학습을 진행하게됩니다. 만약에 G가 X의 분포를 정확하게 복제했을 경우, `Discriminator model D` 는 G가 만들어낸 데이터와 진짜 데이터 X를 구별하지 못합니다. `Discriminator model D` 는 현재 구별하고자 하는 데이터가 학습 데이터로 부터 온 것인지(real data), G로 부터 만들어 진 것인지(fake data)를 판별하여 진짜일 확률을 추측합니다.

#### 솔루션

학습을 시킬 땐 모델이 두개 임으로 Generator 와 Discriminator를 나눠서 생각해야 합니다. 

` Generator(G) `  는 실제와 비슷한 데이터 분포를 생성하고 `Discriminator(D)`  는 진짜와 가짜를 완벽하게 분류하도록 모델을 구성해야합니다. 

논문에서는 솔루션을 얻기 위해 아래와 같이 `D`와 `G`로 이루어진 Minimax problem을 정의하고 있습니다.


$$
\min_G \max_D V(D,G) = \mathbb{E}_{x\sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z\sim p_{z}(z)}[\log(1-D(G(z)))]
$$


$$\mathbb{E}_{x\sim p_{data}(x)}[\log D(x)] $$ : 학습 데이터 x를 Discriminator에 넣었을 경우 나오는 결과를 로그 취했을 때 얻는 기댓값 입니다. 

 $$\mathbb{E}_{z\sim p_{z}(z)}[\log(1-D(G(z)))]$$ :  가짜 데이터 z를 Generator에 넣었을 때 나오는 결과를 Discriminator에 넣었을 경우 나오는 결과값을 log(1 - output)을 했을때 얻는 기대값을 의미합니다.

  D의 성능이 이상적으로 뛰어날 경우, D에 들어온 x가 학습 데이터에서 온 경우 D(x) = 1이 되므로 log1이 되어 첫 항이 0 됩니다. 그리고 G가 생성한 가짜 이미지를 판별 가능하여 D(G(z)) = 0이 되므로 log1이 되어 두번째 항 역시 0이 됩니다. 따라서 D의 최댓값은 `0`이라는 걸 알 수 있습니다. 반대로 G의 성능이 이상적으로 뛰어날 경우 , D(G(z))의 값은 1 이 log0 즉 `-∞`가 최소라는 것을 알 수 있습니다.

  논문에서는 조금 더 이해하기 쉽도록 그림을 예시로 제시하였습니다. 아래 그림을 보면 모델이 어떤 식으로 동작하는지 감을 잡을 수 있습니다.

 ![Gan2](/assets/img/Gan2.png)																*출처 : [Generative Adversarial Nets]( https://arxiv.org/pdf/1406.2661.pdf )* 

초록색 : Generator가 생성한 데이터 분포

검은색 점선 : 실제 데이터 분포

파란색 점선 : Discriminative 분포

그림을 보면 조금 더 와닿는 부분 이 많다.

(a)의 경우 `Generator` 가 아주 형편없는 데이터 분포를 만들어 `Discriminator`가 아주 쉽게 구분 가능합니다 .

하지만 학습을 하면 할수록 `Generator` 가 진짜와 비슷한 분포를 생성하고 결국 (d)에서 보듯이 `Generator` 의 인풋 `z`가 어느 한 부분으로 수렴하게 되고  `Generator` 가 생성한 데이터 분포를 `Discriminator`가 구분하지 못하여 결국 구분할 확률이 $$ 1 \over 2 $$ 이 됨을 알 수 있습니다. 결국 Discriminator는 완벽하게 진짜와 가짜를 구별 못하게 됩니다.

#### Minimax Problem 증명

논문에서는 

1. GAN 의 `minimax problem`이 $$p_g = P_{data}$$ 일 때,  `global optimum`을 가진다.
2. 논문에서 제시된 알고리즘은 `global optimum`을 찾을 수 있다

이 두가지를 단계적으로 접근하여 우리가 원하는 바를 얻을 수 있음을 증명하였습니다. 

##### 1.GAN 의 `minimax problem`이 $$p_g = P_{data}$$ 일 때,  `global optimum`을 가진다.

###### Proposition 1.

​	G가 고정 일 때, optimal discriminator D는 다음과 같다.


$$
D_G^*(x) = {p_{data}(x) \over p_{data}(x) + p_g(x)}
$$


$$
\min_G \max_D V(D,G) = \mathbb{E}_{x\sim p_{data}(x)}[\log D(x)] + \mathbb{E}_{z\sim p_{z}(z)}[\log(1-D(G(z)))]
$$


  위 식 에서 기대값이기 때문에 확률이 같이 곱해져야 합니다.  $$p_z(z)$$는 `Generator`의 분포를 의미함으로 $$p_g(x)$$ 로 바꿔 표현 가능하다. 이에 z가 x에 관하여 바뀌었으니 $$D(G(z))$$ 또한 $$x$$에 관한 식으로 변경 가능하다. $$D(x)$$로 바뀐다. 그렇게 식을 정리하면 


$$
V(G,D) = \int^{}_{x}{p_{data}(x)\log{(D(x))+ p_g(x)\log(1-D(x))}dx}
$$


로 바꿔 적을 수 있다. 여기서 opimum이 되는 곳을 찾아야하기 때문에 미분을 해줘야 한다. 그럼 식은 아래와 같이 나온다.


$$
{P_{data}(x) \over{D(x)}} - {p_g(x) \over 1-D(x)} = 0
$$


 이를 D(x)에 관한 식으로 정리해주면 Proposition 1에서 정의한 식이 나온다는 걸 증명할 수 있다.

 
$$
D_G^*(x) = {p_{data}(x) \over p_{data}(x) + p_g(x)}
$$
 

 결론적으로 Proposition 1에서 나타내고자 하는 것은 G가 고정 되어있을 때 D의 Optimal 상태는 항상 위 식으로 나타낼 수 있다는 것임을 알 수 있다.



우리는 $$D^*_G(x)$$를 조금 더 수식화 하여 간단하게 표현하였기 때문에 G가 고정된 상태에서 아래와 같이 표시할 수 있고 논문에서는 이를 C(G)라고 표기하였다.


$$
\begin{eqnarray}
C(G) = \max_D V(D,G) 
\\  = \mathbb{E}_{x\sim p_{data}(x)}[\log D_G^*(x)] + \mathbb{E}_{x\sim p_{g}(x)}[\log(1-D_G^*(x))] 
\end{eqnarray}
$$



###### Theorem 1.

Main Theorem 에선 D가 global optimum에 잘 도달했다고 가정 했을 때, G가 실제로 `global optimum`를 가지는지, 그리고 어떨 때 `global optimum`을 가지는지 수식으로 증명합니다 .

  우리가 원하는 것은 `generator`가 생성한 데이터가 실제 데이터와 똑같을 경우를 목표로 함으로,   $$p_g = p_{data}$$ 라 하면 $$D^*_G = {1 \over 2}$$가 됨을 알 수 있습니다. 따라서 $$C(G)=\mathbb{E}_{x\sim p_{data}(x)}[-\log(2)] + \mathbb{E}_{x\sim p_{g}(x)}[-\log(2)]$$ 가 된다는 것을 알 수 있고 결론적으로 $$C(G)$$가 $$-log(4)$$로 수렴한다는 것을 알 수 있습니다.

이게 진짜 가능한 값인가? 를 논문에서는 아래와 식을 전개하여 증명하였습니다.


$$
C(G) = -\log(4) + KL(p_{data}||{p_{data} + p_g \over 2}) + KL(p_g||{p_{data} + p_g \over 2})
\\ 
= -log(4) + 2\cdot JSD(p_{data}||p_g)
$$
  

  위 식을 찬찬히 뜯어보자면 `KL()`같은 경우 [Kullback-Leibler Divergence](https://ko.wikipedia.org/wiki/%EC%BF%A8%EB%B0%B1-%EB%9D%BC%EC%9D%B4%EB%B8%94%EB%9F%AC_%EB%B0%9C%EC%82%B0)를 의미하며 근사시 발생하는 정보 손실량의 기댓값을 의미하며. `JSD`같은 경우 [Jensen–Shannon divergence](https://en.wikipedia.org/wiki/Jensen%E2%80%93Shannon_divergence)를 의미하며 두 대등한 확률 분포가 얼마나 닮았는지 측정하는 척도로 쓰인다. 결국 위 식은 식을 계산과정없이 식을 전개해놨다고만 볼 수 있다.

결론적으로 `Theorem1` 이 이야기 하고 싶은 것은  $$p_{data}$$의 distribution 과  $$p_g$$의 distribution에 사이의 차이는 항상 0보다 크거나 같기 때문에 같을 경우에만 `0`을 가지고 그 때 C(G)는 `-log(4)`, 즉 최소값을 가진다. 또한 $$JSD(p_{data}||p_g)$$는 항상 0보다 크거나 같기 때문에 C(G)는 `convex`하다고 볼 수 있다. 

[참고]
$$
KL(p||q) = \sum_i{p_i log{p_i \over q_i}}
$$

$$
JSD(p||q) = {1 \over 2}KL(p||{p+q \over2 })+{1 \over 2}KL(q||{p+q \over2 })
$$



###### proposition 2

> If $$G$$ and $$D$$ have enough capacity, and at each step of Algorithm 1, the discriminator is allowed to reach its optimum given $$G$$, and $$p_g$$  is updated so as to improve the criterion
>
> 

$$
\mathbb{E}_{x\sim p_{data}(x)}[\log D_G^*(x)] + \mathbb{E}_{x\sim p_{g}(x)}[\log(1-D_G^*(x))]
$$

 

  이 논문에서 제안한 알고리즘은 `discriminator` 가 주어진  `G`에 대해 최적화가 될 수 있도록 $$p_g$$ 를 업데이트 하도록 하는 알고리즘을 제안하였습니다.

> Proof. Consider $$V (G, D) = U(pg, D)$$ as a function of pg as done in the above criterion. Note that $$U(pg, D)$$ is convex in $$p_g$$. **The subderivatives of a supremum of convex functions include the derivative of the function at the point where the maximum is attained.** 
>
> In other words, **if $$f(x) = \supα∈A fα(x)$$ and $$fα(x)$$ is convex in $$x$$ for every $$α$$, then $$∂fβ(x) ∈ ∂f$$ if $$β = \arg \supα∈A fα(x)$$**. This is equivalent to computing a gradient descent update for $$p_g$$ at the optimal $$D$$ given the corresponding $$G$$. $$supD$$ $$U(pg, D)$$ is convex in $$p_g$$ with a unique global optima as proven in Thm 1, therefore with sufficiently small updates of $$p_g$$, $$p_g$$ converges to $$p_x$$, concluding the proof.

