컴퓨터 구조 

프로세스의 고성능을 위한 방법

컴퓨터 비용은 감소하고 성능은 높아짐

pipelining :  프로세서가 데이터나 명령어를 지속적으로 가져와서 처리하도록 하는 기법

Branch prediction :  분기 명령어가 프로세서에 들어왔다면 어디로 점프할 것인지 예측해서 점프 명령어의 주소를 가져와서 어떤 명령이 될지 예상함

Superscalar execution :  여기서 스칼라는 명령어의 정수형 연산을 스칼라로 취급 벡터는 배열의 연산, 정수형을 연산하는 것이 여러개로 이루어지도록 하는 기법 한 클럭에 여러개 실행 가능

Data flow analysis :  데이터의 의존성을 분석하여 스케쥴링 최적화

Speculative execution : 다음번엔 어떤 것이 실행 할 것이다 예측하여 패치를 미리 들고 오는 기법

​											(컴퓨터로 어떻게 대충 추측 하는 걸까?)

프로세서를 설계하는 데 중요한 것

​		프로세서는 빠르지만 메모리는 느리다

​		== 메인 메모리보다 더 빠른 cash를 이용하여 극복

​		==버스/인터페이스 기술을 조금더 빠르게 함으로써 메모리 자체가 battlelack 이 되는 현상을 피해야한다.

​		==인터페이스 속도를 더 높여서 성능을 높여야한다.



하드웨어 프로세서의 성능을 높이는 것

​	캐쉬를 사용 하는 것

​	프로세서의 아키텍처나 organization을 고성능으로 계속 바꾸는 노력이 필요하다.

​			병렬형 컴퓨터로 바꾸던가 ex) multicore , pipeline

​			명령어를 고성능으로 바꾸던가

​	Shrinking logic gate size :: 나노 공정으로 더많은 트렌지스터를 집적하여 반도체 기본 성능을 향상하여 프로세서 성능 상향

​	

클락 속도를 높이고 로직 밀도를 높이면 문제점이 생긴다.

소비 전력이 높아짐

​	전력이 높아짐에 따라 발열이 심해짐

​	그래서 대용량 팬이 생김

RC delay가 커질 수 밖에 없다 . (R : resistance  C: capacitance)

​	저항에 의해 열이 생길 수 있고

​	전류의 흐르는 양 자체도 제한을 받는다.

​	 

병렬 컴퓨팅

 1. MultiCore

    Core의 개수를 늘림으로써 전체 프로세서 성능을 높인다.

    2. MIC [Many Integrated Core]

       코어가 많은 아키텍쳐

       성능에선 많이 향상되었지만.

       소프트웨어에 있어서 병렬화할 수 있는 기법이 반드시 필요하다.

    3. GPU [Graphics Processing Unit]

       아주 작은 SIMD 유닛을 수천개 사용하여 그래픽을 처리하는 기법을 사용

       Vector 프로세서와 유사한 구조이다

    4. Amdahl's Law Formula

       프로그래밍 코드 중 F만큼 병렬 처리 가능하고 

       (F-1) 만큼은 병렬처리 불가.

       이 떄 속도 향상이 얼마나 될까?

    $$
    speedup = {{time \; to \; execute \; program \; on \; a \; single \; processor}\over {time \; to \; execute \; program \; on \; N \; parallel \; processors}}\\ = {{T(1-f)+T(f)}\over{T(1-f)+{T(f)\over N}}} \\ = {1 \over (1-f)+{f\over N}}
    $$


    	f가 작다면 병렬효과가 작을 것이다.
    
    ​	$$ N \to \infty$$ 라면  속도향상 비율은 $$1\over(1-f)$$ 이다.
    
    ​	결국 병렬 코어가 아무리 많다라고 하더라도 프로그래밍 병렬이 중요하다.
    
    ​	 f가 중요하다. 결국은 f라는 parallaize code가 많을수록 속도가 빠르다.
    
    5. Little's Law
    
       어떤 프로그램이 정상적인 상태에 도달 했을때 일과, 서비스 시간이 얼마나 걸렸는지 알려주는 시스템 
       $$
       L = \lambda W \\ L : Average \; number \; of \; items\;in\;a\;system\\
       \lambda : Avaerage\;arrival\;rate\\
       W : Average\;wait\;time\;in\;the\;system\;for\;an\;item
       $$
       Little's Law는 성능을 표현할 떄 자주 쓴다.


​       

​       

​       

    System Clock
    
    ​	클럭을 발생시킬 때는 quartz crystal 이 사인 신호를 주면 적절하게 디지털 신호로 바꾼다.
    
    ![image-20200325164605759](C:\Users\USER\AppData\Roaming\Typora\typora-user-images\image-20200325164605759.png)
    
    Calculating the Mean 
    
     1. Arithmetic mean
    
        산술 평균 
    
        $${(x_1+...+x_n)\over n}$$
    
     2. Geometric mean
    
        기하 평균
    
        $$ \sqrt{x_1 *x_2 *...*xn} $$


​        

     3. Harmonic mean
    
        조화평균
    
        $$ n \over {{1 \over x_1}+{1 \over x_2}+...+{1 \over x_n}}$$
    
        값의 변화가 큰 경우를 잘 잡아 낸다.

​        

현재의 컴퓨터는 폰노이만 아키텍쳐로 stored 구조로 명령어와 데이터를 저장하는 구조이다.메모리에 저장하면 주솟값에 의해서 구분된다.

그리고 순차적으로 실행되낟. 

하드웨어 적으로 선으로 연결되어 프로그래밍되어있는 프로그램이

Hardwired program으로 쉽게 바꿀수 없다.



폰노이만 아킥테쳐가 소프트웨어같은 개념을 만들어 냈습니다.



![스크린샷 2020-04-02 오후 4.25.28](/Users/Yoon/Library/Application Support/typora-user-images/스크린샷 2020-04-02 오후 4.25.28.png)

 어떤 동작을 할때 인스트럭션 코드만 바꾼다면 원하는 동작을 할 수 있다.



Software는 뭐냐 

명령어와 코드만 바꾸면 동작을 실행할 수 있는 프로그램

하드웨어의 일부분이 코드를 해석하고 그에 맞는 적절한 제어 신호를 발생해서 곱셈하는 그런 명령어입니다.

소프트웨어는 새로운 코드의 순서를 제공합니다. 그래서 하드웨어를 굳이 재구성할 필요가 없음

명령을 해석을하고 기본적인 연산을 실행하는 그림의 2번쨰 부분이 중요하다

이부분은 CPU에서 가지고 있다 이부분을 Instruction interpreter이라고 한다. 그리고 산술 연산을 가진다.

I/O Components

​	Input

​		외부에서 입력을 받아 드리고 

​	output	

​		CPU로 출력해주는 모듈



MAR : 

​		메모리 어드레스 레지스터라는 것은 메모리 주소값을 저장해주는 것

MBR : 	

​		메모리 버퍼 레지스터는 메모리와 CPU 사이에 데이터가 통신할때 버퍼에저장 하는 것



